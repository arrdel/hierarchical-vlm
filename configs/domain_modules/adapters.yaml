# Domain Adapter Configuration

# LoRA Settings
lora:
  rank: 8
  alpha: 16.0
  dropout: 0.1
  target_modules: ["q_proj", "v_proj"]  # Which layers to apply LoRA to

# Domains
domains:
  sports:
    name: "Sports Videos"
    num_action_classes: 400
    specialization: "temporal action detection"
  
  tutorials:
    name: "Tutorial Videos"
    num_action_classes: 200
    specialization: "procedural understanding"
  
  news:
    name: "News Videos"
    num_action_classes: 100
    specialization: "event detection"
  
  generic:
    name: "Generic Videos"
    num_action_classes: 200
    specialization: "general understanding"

# Adapter Architecture
adapter:
  expansion_factor: 4.0
  activation: "gelu"
  dropout: 0.1
